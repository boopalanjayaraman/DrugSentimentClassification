{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drug Sentiment Prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq96I7MzLycI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Crp33cKMFif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "698484f3-90cb-4b02-cade-c7d861d0ab15"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbA5SxZMGLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sklearn\n",
        "import csv\n",
        "import json\n",
        "import nltk\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hYifMMi5owe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_csv_path = 'drive/My Drive/Colab Notebooks/DrugData/train_original.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx5ATxcZJBTd",
        "colab_type": "code",
        "outputId": "fc52b95e-09ab-4ff6-ee64-77d030978c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df = pd.read_csv(train_csv_path, header=0)\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>I can completely understand why you’d want to ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
              "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
              "      <td>fingolimod</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
              "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
              "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0  ...         2\n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4  ...         2\n",
              "2  fe809672251f6bd0d986e00380f48d047c7e7b76  ...         2\n",
              "3  bd22104dfa9ec80db4099523e03fae7a52735eb6  ...         2\n",
              "4  b227688381f9b25e5b65109dd00f7f895e838249  ...         1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMyXJwNuJ2pm",
        "colab_type": "code",
        "outputId": "2ff89314-e0f1-4e67-f656-296a1ace2b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5279.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.607691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.687203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment\n",
              "count  5279.000000\n",
              "mean      1.607691\n",
              "std       0.687203\n",
              "min       0.000000\n",
              "25%       1.000000\n",
              "50%       2.000000\n",
              "75%       2.000000\n",
              "max       2.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WjiNaVdJGnh",
        "colab_type": "code",
        "outputId": "09242b87-890b-4e71-803a-3988935e2178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_2_set = train_df[['text', 'drug', 'sentiment']][train_df['sentiment'] == 2]\n",
        "sentiment_1_set = train_df[['text', 'drug', 'sentiment']][train_df['sentiment'] == 1]\n",
        "sentiment_0_set = train_df[['text', 'drug', 'sentiment']][train_df['sentiment'] == 0]\n",
        "print(len(sentiment_2_set))\n",
        "print(len(sentiment_1_set))\n",
        "print(len(sentiment_0_set))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3825\n",
            "837\n",
            "617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "133-Rk8YKiA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_data_from_df(df, frac):\n",
        "  if frac <= 1.0:\n",
        "    temp_df = df.sample(frac = frac, replace=False)\n",
        "    return temp_df\n",
        "  else:\n",
        "    temp_df = df.sample(frac = frac, replace=True)\n",
        "    return temp_df\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYP5DM9SMEH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows_needed_for_0 = 900\n",
        "rows_needed_for_1 = 1200\n",
        "rows_needed_for_2 = 1000\n",
        "sentiment_2_set = sample_data_from_df(sentiment_2_set, rows_needed_for_2/len(sentiment_2_set))\n",
        "sentiment_1_set = sample_data_from_df(sentiment_1_set, rows_needed_for_1/len(sentiment_1_set))\n",
        "sentiment_0_set = sample_data_from_df(sentiment_0_set, rows_needed_for_2/len(sentiment_0_set))\n",
        "\n",
        "total_train_df = pd.concat([sentiment_2_set,sentiment_1_set,sentiment_0_set])\n",
        "total_train_df = total_train_df.sample(frac = 1, replace=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAP2uv3mM0XB",
        "colab_type": "code",
        "outputId": "2b8e5b6c-5947-470d-ecdc-fc0f30584168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(total_train_df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHdoxZ6HNRj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_texts = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y85WeHCBNVm1",
        "colab_type": "code",
        "outputId": "6be114d1-9105-4284-9921-7d10669e5ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''with open(train_csv_path, 'r', encoding='utf-8') as f:\n",
        "  input_data = csv.reader(f)\n",
        "  \n",
        "  for row in input_data:\n",
        "    all_texts.append(row)'''\n",
        "\n",
        "all_texts = []\n",
        "for _, row in total_train_df.iterrows():\n",
        "  all_texts.append(row)\n",
        "  \n",
        "print(len(all_texts))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqzUPAT9OUz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages = [text[0] for text in all_texts]\n",
        "sentiments = [text[2] for text in all_texts]\n",
        "drug_info = [text[1] for text in all_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FiubR1_ptMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_drug_info = []\n",
        "for index, item in train_df[['drug']].iterrows():\n",
        "  all_drug_info.append(item[0].replace(' ', '-'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMvB9vVqb_G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 0\n",
        "for message in messages:\n",
        "  drug_name_without_space = drug_info[index].replace(' ', '-')\n",
        "  messages[index] = message.replace(drug_info[index], drug_name_without_space)\n",
        "  drug_info[index] = drug_name_without_space\n",
        "  index += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgL3FrrVOmR6",
        "colab_type": "code",
        "outputId": "b9d669bc-42fd-43b4-cba8-ded432ebf057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(messages[0])\n",
        "print(sentiments[:20])\n",
        "print(drug_info[:10])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello! i hope you are doing well. my daughter had optic neuritis and was hospitalized in April 2018. her neurologist is recommending two drugs, either Copaxone and Ocrevus.. and we are unsure of what to do. Can you please tell me what course of medication you are on now? Good luck to you.\n",
            "[1, 2, 0, 0, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 0, 2, 1]\n",
            "['ocrevus', 'gilenya', 'ocrelizumab', 'keytruda', 'tarceva', 'ocrelizumab', 'ocrelizumab', 'gilenya', 'entyvio', 'ocrevus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swNJcZgDOthY",
        "colab_type": "code",
        "outputId": "d3803480-5b1f-473a-9c0e-982a96e38bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#0 - positive\n",
        "#1 - negative\n",
        "#2 - neutral\n",
        "from collections import Counter\n",
        "sentiment_counter = Counter(sentiments)\n",
        "sentiment_counter.most_common()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1200), (2, 1000), (0, 1000)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hmJFD_vO9aG",
        "colab_type": "code",
        "outputId": "47d93290-73fb-4879-e0ab-0ef06e979d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "drugs_set = set(all_drug_info)\n",
        "print(drugs_set)\n",
        "print(len(drugs_set)) #original - 102"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mavenclad', 'atezolizumab', 'crizotinib', 'gefitinib', 'giotrif', 'tofacitinib', 'necitumumab', 'guselkumab', 'fingolimod', 'brigatinib', 'panretinal-photocoagulation', 'tafinlar', 'nivolumabb', 'osimertinib', 'ceritinib', 'certolizumab-pegol', 'ipilimumab', 'brolucizumab', 'rhumab-2h7', 'durvalumab', 'entrectinib', 'laser-photocoagulation', 'vedolizumab', 'simponi', 'arzerra', 'ct-p13', 'alectinib', 'alectnib', 'tagrisso', 'cladribine', 'trametinib', 'amjevita', 'alunbrig', 'movectro', 'tarceva', 'ozurdex', 'alecensa', 'tecentriq', 'alemtuzumab', 'pegaptanib', 'ustekinumab', 'opdivo', 'renflexis', 'lucentis', 'ofatumumab', 'pembrolizumab', 'zykadia', 'avastin', 'mekinist', 'vitrectomy', 'stelara', 'ocrevus', 'pemetrexed', 'imfinzi', 'keytruda', 'gilotrif', 'eylea', 'yervoy', 'erlotinib', 'golimumab', 'pemrolizumab', 'dabrafenib', 'cyramza', 'nivolumab', 'xalkori', 'remicade', 'filgotinib', 'lorlatinib', 'siponimod', 'ranibizumab', 'bevacizumab', 'cimzia', 'ixifi', 'macugen', 'teriflunomide', 'lemtrada', 'alimta', 'pemetrexed-disodium', 'aflibercept', 'humira', 'pan-retinal-photocoagulation', 'inflectra', 'afatinib', 'photodynamic-therapy', 'aubagio', 'upadacitinib', 'ocrelizumab', 'dexamethasone-implant', 'crizotnib', 'dexamethasone', 'ketruda', 'infliximab-dyyb', 'entyvio', 'geftinib', 'remsima', 'pf-00547659', 'tysabri', 'cyltezo', 'almita', 'iressa', 'gilenya', 'portrazza'}\n",
            "102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlNrQiDYPG2N",
        "colab_type": "code",
        "outputId": "9cf994fd-081f-4a95-b2fa-9280ad467d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI5EjfqsTdrp",
        "colab_type": "code",
        "outputId": "afbdb756-8c66-416b-f61a-5f261b400a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.224)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.8.19)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.83)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.6.16)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.224)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiWAyk9Ja3Z2",
        "colab_type": "code",
        "outputId": "ea5689ad-f2aa-433e-c806-0500841590ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.224)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.8.19)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.5)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.224)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.6.16)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.224->boto3->pytorch_pretrained_bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVVRCoMbSbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0kn07V0bxVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_870Xryb5Cz",
        "colab_type": "code",
        "outputId": "a6ef92ef-c3a8-4539-ec2c-8e7e68c271ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = 'all the world is a stage'\n",
        "temp_tokens = tokenizer.tokenize(text)\n",
        "print(temp_tokens)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['all', 'the', 'world', 'is', 'a', 'stage']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upjmz1ghcDNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "  def __init__(self, hidden_size, eps=1e-12):\n",
        "    super(BertLayerNorm, self).__init__()\n",
        "    self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "    self.variance_epsilon = eps\n",
        "    \n",
        "  def forward(self, x):\n",
        "    u = x.mean(-1, keepdim=True)\n",
        "    s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "    x = (x - u)/ torch.sqrt(s + self.variance_epsilon)\n",
        "    return self.weight * x + self.bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfHi66CjcP8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(nn.Module):\n",
        "  def __init__(self, num_labels = 2):\n",
        "    super(BertForSequenceClassification, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    #self.bert = BertModel.from_pretrained('bert-large-uncased')\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "    \n",
        "    nn.init.xavier_normal_(self.classifier.weight)\n",
        "    \n",
        "  def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "    _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "    logits = self.classifier(pooled_output)\n",
        "    \n",
        "    return logits\n",
        "    \n",
        "  def freeze_bert_encoder(self):\n",
        "    for param in self.bert.parameters():\n",
        "      param.requires_grad = False\n",
        "      \n",
        "  def unfreeze_bert_encoder(self):\n",
        "    for param in self.bert.parameters():\n",
        "      param.requires_grad = True\n",
        "      \n",
        "\n",
        "       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiWoDhoSgJxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from pytorch_transformers import BertConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLLoxRDzbCAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertConfig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2qG39BygT7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up model\n",
        "#bert-base-uncased: hidden_size:768 hidden_layers:12 attention_heads:12\n",
        "#bert-large-uncased: hidden_size:1024 hidden_layers:24 attention_heads:16\n",
        "\n",
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768, \n",
        "                    num_hidden_layers=12, num_attention_heads=12, \n",
        "                    intermediate_size=3072)\n",
        "\n",
        "num_labels = 3\n",
        "model = BertForSequenceClassification(num_labels=num_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cr2u4bEFDAt",
        "colab_type": "code",
        "outputId": "04ef4fd8-17bc-4609-a47a-d6e2f55b3b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# simple test for model - logits\n",
        "tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(temp_tokens)])\n",
        "logits = model(tokens_tensor)\n",
        "print('logits: ', logits)\n",
        "print(len(messages))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logits:  tensor([[ 0.7158,  0.4151, -0.7481]], grad_fn=<AddmmBackward>)\n",
            "3200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faWaXx8_k4B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_sentences_count = 1 #meaning above 1 + below 1 + sentence with the drug\n",
        "\n",
        "# text preprocessing function\n",
        "def pre_process_text(message, drug_in_context, print_info=False):\n",
        "  sentences = message.lower().split('.')\n",
        "  \n",
        "  indices = set()\n",
        "  index = 0\n",
        "  \n",
        "   \n",
        "  for sentence in sentences:\n",
        "    if drug_in_context in sentence:\n",
        "      indices.add(index)\n",
        "      #add sentences before\n",
        "      if index >= 1:\n",
        "        indices.add(index -1)\n",
        "      #add sentences afterwards\n",
        "      if (index < len(sentences) - 1) and index >= 0: \n",
        "        indices.add(index+1) \n",
        "    index += 1\n",
        "  \n",
        "  if print_info:\n",
        "    print(drug_in_context)\n",
        "    print(len(sentences))\n",
        "    print(indices)\n",
        "   \n",
        "  \n",
        "  new_message = ''\n",
        "  \n",
        "  \n",
        "  additional_context = 'About {}. '.format(drug_in_context).lower()\n",
        "  new_message += additional_context\n",
        "  \n",
        "  for ind in indices:\n",
        "    new_message += ' ' + sentences[ind]\n",
        "  \n",
        "  #new_message = new_message.replace(drug_in_context, 'drugincontext')\n",
        "  \n",
        "  return new_message\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsT7OWyIrhR0",
        "colab_type": "code",
        "outputId": "4a59ddb1-19f5-45c2-d31e-60751f83cb7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_set = set(stopwords.words('english'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRE0YTMLH18G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5aabeabe-24f6-4c55-f7a5-0c17947a684b"
      },
      "source": [
        "print(stop_words_set)\n",
        "print(len(stop_words_set))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'itself', 'more', 'whom', 'no', 'do', 'any', 'o', 'other', 'didn', 'but', 'ain', 'and', 'doesn', 'this', 'that', 'on', 'during', 'over', 'few', 'aren', 'our', 'where', 'both', 'should', 'against', 'below', 'it', 'about', 'all', \"hadn't\", 'further', 'yourself', 'ma', 'him', \"she's\", 'what', 'above', 'now', 'isn', 'to', 'then', 'are', \"should've\", 'hers', 'there', \"mightn't\", 'up', 'before', 'mightn', 'some', 'too', \"that'll\", 'will', 'because', 'again', 'is', 'doing', 'an', 'does', 'by', 'each', \"you've\", 's', 'theirs', 'just', 'your', \"it's\", 'y', 'mustn', 'i', \"weren't\", 'be', \"you'd\", 'ourselves', 'haven', 'off', 'wouldn', 'not', 'those', 'you', 'were', \"wouldn't\", \"hasn't\", 'than', 'needn', 'with', \"haven't\", 'don', 'until', 're', 'own', 'they', 'she', 'when', 'wasn', 'if', \"mustn't\", 'through', 'yourselves', 'here', 'herself', 'we', 'themselves', \"shouldn't\", 'only', 'll', 'm', 'been', 'himself', 'having', 'how', 'my', 'them', 'can', 'me', 'their', 'has', 'the', 'very', 'most', \"isn't\", \"needn't\", 'have', 'in', 'couldn', 'her', \"you're\", 'yours', 'or', 'same', 'into', 'out', 'am', \"you'll\", 'under', 'hadn', 'down', 'its', 't', 'at', 'won', 'shan', 'd', 'shouldn', 'his', \"aren't\", 'nor', 'between', 'weren', 'for', 'ours', 'these', 'of', 'as', 'he', 've', \"won't\", 'was', 'after', \"wasn't\", 'such', 'which', 'once', 'who', \"doesn't\", 'being', 'why', 'did', 'myself', 'so', \"didn't\", 'while', \"couldn't\", 'a', 'had', 'hasn', \"shan't\", 'from', \"don't\"}\n",
            "179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKm10dPHP2eo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7dcbca0-49aa-473f-b2b9-bd31820fde13"
      },
      "source": [
        "negative_polarity_stop_words = ['doesn', 'hadn', 'shan', 'nor', 'wasn', 'hasn', \"mightn't\", \"mustn't\", \"wasn't\", 'does', 'don', 'shouldn', 'won', \"hasn't\", 'couldn', \"needn't\", \"couldn't\", \"won't\", 'not', \"hadn't\", \"wouldn't\", \"aren't\", \"weren't\", \"shan't\", \"isn't\", 'weren', 'wouldn',  \"didn't\", \"don't\", \"haven't\", 'didn', 'neither', 'needn', 'haven', 'isn', 'mustn', 'mightn', \"doesn't\", 'ain', 'aren', \"shouldn't\", \"never\", \"neva\", \"dint\", \"din\", \"no\"]\n",
        "negative_polarity_stop_words_set = set(negative_polarity_stop_words)\n",
        "\n",
        "#remove these from stop words so they can be retained in the text to indicate negative polarity\n",
        "for wrd in negative_polarity_stop_words:\n",
        "  if wrd in stop_words_set:\n",
        "    stop_words_set.remove(wrd)\n",
        "\n",
        "#arrange more stop words\n",
        "new_stop_words = []\n",
        "    \n",
        "def process_stop_words(stop_word_string, stop_words_set, new_stop_words):\n",
        "  for wrd in stop_word_string.split(' '):\n",
        "    if wrd not in stop_words_set:\n",
        "      new_stop_words.append(wrd)\n",
        "    \n",
        "stop_words_new = \"a about after all also always am an and any each are at be been being but by can could did do does doing else for from  had has have how i if ill i'm in into is it its i've just like many may me more most much now of only or our some something than that the their them then they thing this to up us very was way we what when where which who why will with without you your youre etc every\"\n",
        "stop_words_days = 'sunday monday tuesday wednesday thursday friday saturday yesterday tomorrow today afternoon morning evening tonight night'\n",
        "stop_words_months = 'january jan february feb march mar april apr may june jun july jul august aug september sep october oct november nov december dec'\n",
        "stop_words_numeric = 'one two three four five six seven eight nine ten twenty thirty forty fify hundred hundreds thousand thousands tens first second third fourth fifth sixth seventh eighth ninth tenth eleventh twelfth thirteenth fourteenth fifteenth twentieth hundredth thousandth'\n",
        "\n",
        "process_stop_words(stop_words_new, stop_words_set, new_stop_words)\n",
        "process_stop_words(stop_words_days, stop_words_set, new_stop_words)\n",
        "process_stop_words(stop_words_months, stop_words_set, new_stop_words)\n",
        "process_stop_words(stop_words_numeric, stop_words_set, new_stop_words)\n",
        "\n",
        "for wrd in stop_words_set:\n",
        "  if '\\'' in wrd:\n",
        "    new_stop_words.append(wrd.replace('\\'', ''))\n",
        "\n",
        "for wrd in new_stop_words:\n",
        "  stop_words_set.add(wrd)\n",
        "  \n",
        "print(len(stop_words_set))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0C7SLKTMDct",
        "colab_type": "code",
        "outputId": "f60c4c1b-d3b4-43d9-c2bf-e39ddc361205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import lemmatizer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "print(lemmatizer.lemmatize('corpora'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-22Wg1zWeA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "90716c68-8c3f-4eb8-8a62-291ac0d854b1"
      },
      "source": [
        "#deal with word frequency\n",
        "from collections import Counter\n",
        "vocab = Counter()\n",
        "for message in messages:\n",
        "  words = message.split(' ')\n",
        "  for word in words:\n",
        "    if len(word) > 1:\n",
        "      vocab.update([word])\n",
        "      \n",
        "print(vocab.most_common(100))\n",
        "print(len(vocab.most_common()))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 31924), ('to', 23714), ('of', 22949), ('and', 22814), ('in', 14950), ('for', 10863), ('is', 10538), ('with', 10038), ('that', 9248), ('or', 6748), ('on', 6677), ('have', 6256), ('was', 6214), ('my', 5975), ('it', 5713), ('be', 5448), ('you', 5237), ('as', 4891), ('are', 4868), ('not', 4585), ('this', 4187), ('at', 3715), ('but', 3662), ('your', 3654), ('The', 3599), ('had', 3201), ('from', 3142), ('patients', 3047), ('has', 2797), ('if', 2739), ('an', 2696), ('may', 2682), ('by', 2670), ('been', 2657), ('can', 2459), ('about', 2413), ('so', 2343), ('treatment', 2337), ('MS', 2337), ('will', 2283), ('more', 2238), ('me', 2203), ('other', 2061), ('all', 1980), ('were', 1938), ('which', 1866), ('after', 1836), ('they', 1725), ('cancer', 1716), ('get', 1623), ('no', 1605), ('any', 1589), ('also', 1571), ('one', 1559), ('It', 1553), ('like', 1549), ('when', 1545), ('some', 1540), ('would', 1532), ('who', 1488), ('there', 1487), ('just', 1457), ('do', 1443), ('first', 1428), ('very', 1409), ('new', 1393), ('than', 1390), ('we', 1382), ('am', 1371), ('disease', 1367), ('side', 1363), ('up', 1348), ('This', 1331), ('drug', 1274), ('what', 1250), ('years', 1224), ('people', 1212), ('time', 1199), ('In', 1193), ('out', 1165), ('these', 1137), ('clinical', 1132), ('months', 1130), ('My', 1109), ('doctor', 1087), ('If', 1078), ('then', 1054), ('only', 1053), ('he', 1042), ('because', 1021), ('now', 1020), ('how', 1015), ('should', 996), ('two', 985), ('know', 968), ('trial', 960), ('effects', 948), ('could', 942), ('her', 932), ('much', 923)]\n",
            "59165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD-Xy0vCXlGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "036fe11e-91b5-4005-988a-0d6afc51921f"
      },
      "source": [
        "#words with frequency above the threshold\n",
        "count = 0\n",
        "word_freq_threshold = 5\n",
        "for word in vocab:\n",
        "  if vocab[word] >= word_freq_threshold:\n",
        "    count += 1\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOQI5zeAdvwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre processing tokens. \n",
        "# returns token ids \n",
        "def process_tokens(text, tokenizer, max_seq_length = 256, return_tensor=False, printInfo=False):\n",
        "  #remove symbols from text\n",
        "  text = remove_symbols(text)\n",
        "  #tokenize the plain text \n",
        "  tokenized_text = tokenizer.tokenize(text)\n",
        "  #remove stop words\n",
        "  tokenized_text = remove_stopwords(tokenized_text)\n",
        "  \n",
        "  #clip data that is more than max length\n",
        "  if len(tokenized_text) > max_seq_length:\n",
        "    tokenized_text = tokenized_text[:max_seq_length]\n",
        "    \n",
        "  if printInfo:\n",
        "    print(tokenized_text)\n",
        "    \n",
        "  #convert the tokens to ids\n",
        "  ids_text = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    \n",
        "  #pad the data ids with zeros if the length was less than max seq length\n",
        "  if len(ids_text) < max_seq_length:\n",
        "    padding_array = [0] * (max_seq_length - len(ids_text))\n",
        "    ids_text += padding_array\n",
        "    \n",
        "  if return_tensor:\n",
        "    return torch.tensor(ids_text)\n",
        "  \n",
        "  return ids_text\n",
        "\n",
        "def remove_stopwords(tokenized_text):\n",
        "  result = []\n",
        "  for token in tokenized_text:\n",
        "    if token in stop_words_set:\n",
        "      continue\n",
        "    '''if token in negative_polarity_stop_words_set:\n",
        "      result.append(\"negative\")'''\n",
        "    '''if (token not in vocab) or (vocab[token] >= word_freq_threshold):\n",
        "      result.append(token)'''\n",
        "    result.append(token)\n",
        "  \n",
        "  return result\n",
        "\n",
        "def remove_symbols(text):\n",
        "  #remove urls\n",
        "  text = re.sub(r'https?:\\/\\/[\\w\\d\\.\\/\\-\\?\\=#]*', '', text)\n",
        "  #remove numbers\n",
        "  text = re.sub(r'\\d', '', text)\n",
        "  #removes symbols except . ? ! [] -\n",
        "  text = re.sub(r'[^!\\?\\-\\.\\w_\\s]+','', text)\n",
        "  #text = re.sub(r'[~`\"@#$%{}:;,\\+\\(\\)\\*&<>]', '', text) \n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM4MrZLouhYp",
        "colab_type": "code",
        "outputId": "f0567e09-de2a-44bc-b933-fae1656889c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#test support methods\n",
        "test_str = 'this is a review about ocrelizumab!. he + means * drug, that, & everyone is buzzing about in the ms circles (who knew there were ms circles? well, there are ); the new drug should be approved at the end of march, so my last tysabri infusion will be in march i think we want to put you on the new '\n",
        "test_tokens_1 = test_str.split(' ')\n",
        "print(remove_stopwords(test_tokens_1))\n",
        "print(remove_symbols(test_str))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['review', 'ocrelizumab!.', '+', 'means', '*', 'drug,', 'that,', '&', 'everyone', 'buzzing', 'ms', 'circles', '(who', 'knew', 'ms', 'circles?', 'well,', ');', 'new', 'drug', 'approved', 'end', 'march,', 'last', 'tysabri', 'infusion', 'think', 'want', 'put', 'new']\n",
            "this is a review about ocrelizumab!. he  means  drug that  everyone is buzzing about in the ms circles who knew there were ms circles? well there are  the new drug should be approved at the end of march so my last tysabri infusion will be in march i think we want to put you on the new \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aIZsnikoe0m",
        "colab_type": "code",
        "outputId": "55201fa2-174e-4835-ccee-ff12ae768dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "#test preprocessing function\n",
        "ind = 10\n",
        "test_message = pre_process_text(messages[ind], drug_info[ind], True)\n",
        "print(test_message)\n",
        "tokens_output = process_tokens(test_message, tokenizer, return_tensor=True, printInfo=True)\n",
        "print(tokens_output)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gilenya\n",
            "22\n",
            "{0, 1, 2, 3, 4, 5, 16, 17, 18}\n",
            "about gilenya.  from ms news today, august 29, 2016:  quote gilenya-like therapy shows benefit in secondary progressive ms patients in phase 3 trial ines martins, phd patients with secondary progressive multiple sclerosis (spms) who were treated with baf312 (siponimod), a sphingosine-1-phosphate (s1p) inhibitor, in a phase 3 clinical trial showed a significantly reduced risk for disability progression compared to placebo, novartis recently announced  baf312 is a selective modulator of specific types of the s1p receptor  this receptor is commonly found at the surface of immune cells that infiltrate and induce damage in the central nervous system (cns), leading to loss of function in ms patients  similar to gilenya (fingolimod), baf312 works by binding to these specific receptors and preventing the migration and activation of immune cells in the cns  baf312, however, binds more selectively to specific s1p receptors than gilenya, particularly to s1p-1 and s1p-5, and is thus expected to avoid lymphopenia (an abnormally low level of lymphocytes, a type of white blood cell, in the blood), one of the more common side effects of gilenya  the expand phase 3 study (nct01665144) is designed to compare the efficacy and safety of baf312 versus placebo in patients with spms  we look forward to sharing the results at the upcoming ectrims congress, and thank all of the study participants and investigators ” novartis is also the maker of gilenya (fingolimod), which was approved by the u s\n",
            "['gil', '##en', '##ya', '.', 'ms', 'news', 'quote', 'gil', '##en', '##ya', '-', 'therapy', 'shows', 'benefit', 'secondary', 'progressive', 'ms', 'patients', 'phase', 'trial', '##es', 'martins', 'phd', 'patients', 'secondary', 'progressive', 'multiple', 'sc', '##ler', '##osis', 'sp', '##ms', 'treated', 'ba', '##f', 'sip', '##oni', '##mo', '##d', 'sp', '##hing', '##osi', '##ne', '-', '-', 'phosphate', 'sp', 'inhibitor', 'phase', 'clinical', 'trial', 'showed', 'significantly', 'reduced', 'risk', 'disability', 'progression', 'compared', 'place', '##bo', 'nova', '##rti', '##s', 'recently', 'announced', 'ba', '##f', 'selective', 'mod', '##ulator', 'specific', 'types', 'sp', 'receptor', 'receptor', 'commonly', 'found', 'surface', 'immune', 'cells', 'infiltrate', 'induce', 'damage', 'central', 'nervous', 'system', 'cn', '##s', 'leading', 'loss', 'function', 'ms', 'patients', 'similar', 'gil', '##en', '##ya', 'fin', '##gol', '##imo', '##d', 'ba', '##f', 'works', 'binding', 'specific', 'receptors', 'preventing', 'migration', 'activation', 'immune', 'cells', 'cn', '##s', 'ba', '##f', 'however', 'binds', 'selective', '##ly', 'specific', 'sp', 'receptors', 'gil', '##en', '##ya', 'particularly', 'sp', '-', 'sp', '-', 'thus', 'expected', 'avoid', 'l', '##ym', '##ph', '##open', '##ia', 'abnormal', '##ly', 'low', 'level', 'l', '##ym', '##ph', '##ocytes', 'type', 'white', 'blood', 'cell', 'blood', 'common', 'side', 'effects', 'gil', '##en', '##ya', 'expand', 'phase', 'study', 'nc', '##t', 'designed', 'compare', 'efficacy', 'safety', 'ba', '##f', 'versus', 'place', '##bo', 'patients', 'sp', '##ms', 'look', 'forward', 'sharing', 'results', 'upcoming', 'ec', '##tri', '##ms', 'congress', 'thank', 'study', 'participants', 'investigators', 'nova', '##rti', '##s', 'maker', 'gil', '##en', '##ya', 'fin', '##gol', '##imo', '##d', 'approved', 'u']\n",
            "tensor([13097,  2368,  3148,  1012,  5796,  2739, 14686, 13097,  2368,  3148,\n",
            "         1011,  7242,  3065,  5770,  3905,  6555,  5796,  5022,  4403,  3979,\n",
            "         2229, 19953,  8065,  5022,  3905,  6555,  3674,  8040,  3917, 12650,\n",
            "        11867,  5244,  5845,  8670,  2546, 10668, 10698,  5302,  2094, 11867,\n",
            "        12053, 20049,  2638,  1011,  1011, 17344, 11867, 24054,  4403,  6612,\n",
            "         3979,  3662,  6022,  4359,  3891, 11980, 14967,  4102,  2173,  5092,\n",
            "         6846, 28228,  2015,  3728,  2623,  8670,  2546, 13228, 16913, 20350,\n",
            "         3563,  4127, 11867, 10769, 10769,  4141,  2179,  3302, 11311,  4442,\n",
            "        29543, 19653,  4053,  2430,  6091,  2291, 27166,  2015,  2877,  3279,\n",
            "         3853,  5796,  5022,  2714, 13097,  2368,  3148, 10346, 24141, 16339,\n",
            "         2094,  8670,  2546,  2573,  8031,  3563, 13833, 10723,  9230, 13791,\n",
            "        11311,  4442, 27166,  2015,  8670,  2546,  2174, 20817, 13228,  2135,\n",
            "         3563, 11867, 13833, 13097,  2368,  3148,  3391, 11867,  1011, 11867,\n",
            "         1011,  2947,  3517,  4468,  1048, 24335,  8458, 26915,  2401, 19470,\n",
            "         2135,  2659,  2504,  1048, 24335,  8458, 28788,  2828,  2317,  2668,\n",
            "         3526,  2668,  2691,  2217,  3896, 13097,  2368,  3148,  7818,  4403,\n",
            "         2817, 13316,  2102,  2881, 12826, 21150,  3808,  8670,  2546,  6431,\n",
            "         2173,  5092,  5022, 11867,  5244,  2298,  2830,  6631,  3463,  9046,\n",
            "        14925, 18886,  5244,  3519,  4067,  2817,  6818, 14766,  6846, 28228,\n",
            "         2015,  9338, 13097,  2368,  3148, 10346, 24141, 16339,  2094,  4844,\n",
            "         1057,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwT7w3pep-Vt",
        "colab_type": "code",
        "outputId": "f29fb894-1228-40b2-f8d9-a9356c3d742c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# sample pipeline of text \n",
        "test_tokens = tokenizer.tokenize(test_message)\n",
        "test_tokens_ids = tokenizer.convert_tokens_to_ids(test_tokens)\n",
        "\n",
        "print(test_tokens)\n",
        "print(test_tokens_ids)\n",
        "print(len(test_tokens_ids))\n",
        "\n",
        "test_tokens_tensor = torch.tensor([test_tokens_ids])\n",
        "print('is tensor: ', type(test_tokens_tensor) == type(torch.Tensor()))\n",
        "print(test_tokens_tensor)\n",
        "\n",
        "logits = model(tokens_tensor)\n",
        "print(logits)\n",
        "\n",
        "result = F.softmax(logits, dim=1)\n",
        "print(result)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['about', 'gil', '##en', '##ya', '.', 'from', 'ms', 'news', 'today', ',', 'august', '29', ',', '2016', ':', 'quote', 'gil', '##en', '##ya', '-', 'like', 'therapy', 'shows', 'benefit', 'in', 'secondary', 'progressive', 'ms', 'patients', 'in', 'phase', '3', 'trial', 'in', '##es', 'martins', ',', 'phd', 'patients', 'with', 'secondary', 'progressive', 'multiple', 'sc', '##ler', '##osis', '(', 'sp', '##ms', ')', 'who', 'were', 'treated', 'with', 'ba', '##f', '##31', '##2', '(', 'sip', '##oni', '##mo', '##d', ')', ',', 'a', 'sp', '##hing', '##osi', '##ne', '-', '1', '-', 'phosphate', '(', 's', '##1', '##p', ')', 'inhibitor', ',', 'in', 'a', 'phase', '3', 'clinical', 'trial', 'showed', 'a', 'significantly', 'reduced', 'risk', 'for', 'disability', 'progression', 'compared', 'to', 'place', '##bo', ',', 'nova', '##rti', '##s', 'recently', 'announced', 'ba', '##f', '##31', '##2', 'is', 'a', 'selective', 'mod', '##ulator', 'of', 'specific', 'types', 'of', 'the', 's', '##1', '##p', 'receptor', 'this', 'receptor', 'is', 'commonly', 'found', 'at', 'the', 'surface', 'of', 'immune', 'cells', 'that', 'infiltrate', 'and', 'induce', 'damage', 'in', 'the', 'central', 'nervous', 'system', '(', 'cn', '##s', ')', ',', 'leading', 'to', 'loss', 'of', 'function', 'in', 'ms', 'patients', 'similar', 'to', 'gil', '##en', '##ya', '(', 'fin', '##gol', '##imo', '##d', ')', ',', 'ba', '##f', '##31', '##2', 'works', 'by', 'binding', 'to', 'these', 'specific', 'receptors', 'and', 'preventing', 'the', 'migration', 'and', 'activation', 'of', 'immune', 'cells', 'in', 'the', 'cn', '##s', 'ba', '##f', '##31', '##2', ',', 'however', ',', 'binds', 'more', 'selective', '##ly', 'to', 'specific', 's', '##1', '##p', 'receptors', 'than', 'gil', '##en', '##ya', ',', 'particularly', 'to', 's', '##1', '##p', '-', '1', 'and', 's', '##1', '##p', '-', '5', ',', 'and', 'is', 'thus', 'expected', 'to', 'avoid', 'l', '##ym', '##ph', '##open', '##ia', '(', 'an', 'abnormal', '##ly', 'low', 'level', 'of', 'l', '##ym', '##ph', '##ocytes', ',', 'a', 'type', 'of', 'white', 'blood', 'cell', ',', 'in', 'the', 'blood', ')', ',', 'one', 'of', 'the', 'more', 'common', 'side', 'effects', 'of', 'gil', '##en', '##ya', 'the', 'expand', 'phase', '3', 'study', '(', 'nc', '##t', '##01', '##66', '##51', '##44', ')', 'is', 'designed', 'to', 'compare', 'the', 'efficacy', 'and', 'safety', 'of', 'ba', '##f', '##31', '##2', 'versus', 'place', '##bo', 'in', 'patients', 'with', 'sp', '##ms', 'we', 'look', 'forward', 'to', 'sharing', 'the', 'results', 'at', 'the', 'upcoming', 'ec', '##tri', '##ms', 'congress', ',', 'and', 'thank', 'all', 'of', 'the', 'study', 'participants', 'and', 'investigators', '”', 'nova', '##rti', '##s', 'is', 'also', 'the', 'maker', 'of', 'gil', '##en', '##ya', '(', 'fin', '##gol', '##imo', '##d', ')', ',', 'which', 'was', 'approved', 'by', 'the', 'u', 's']\n",
            "[2055, 13097, 2368, 3148, 1012, 2013, 5796, 2739, 2651, 1010, 2257, 2756, 1010, 2355, 1024, 14686, 13097, 2368, 3148, 1011, 2066, 7242, 3065, 5770, 1999, 3905, 6555, 5796, 5022, 1999, 4403, 1017, 3979, 1999, 2229, 19953, 1010, 8065, 5022, 2007, 3905, 6555, 3674, 8040, 3917, 12650, 1006, 11867, 5244, 1007, 2040, 2020, 5845, 2007, 8670, 2546, 21486, 2475, 1006, 10668, 10698, 5302, 2094, 1007, 1010, 1037, 11867, 12053, 20049, 2638, 1011, 1015, 1011, 17344, 1006, 1055, 2487, 2361, 1007, 24054, 1010, 1999, 1037, 4403, 1017, 6612, 3979, 3662, 1037, 6022, 4359, 3891, 2005, 11980, 14967, 4102, 2000, 2173, 5092, 1010, 6846, 28228, 2015, 3728, 2623, 8670, 2546, 21486, 2475, 2003, 1037, 13228, 16913, 20350, 1997, 3563, 4127, 1997, 1996, 1055, 2487, 2361, 10769, 2023, 10769, 2003, 4141, 2179, 2012, 1996, 3302, 1997, 11311, 4442, 2008, 29543, 1998, 19653, 4053, 1999, 1996, 2430, 6091, 2291, 1006, 27166, 2015, 1007, 1010, 2877, 2000, 3279, 1997, 3853, 1999, 5796, 5022, 2714, 2000, 13097, 2368, 3148, 1006, 10346, 24141, 16339, 2094, 1007, 1010, 8670, 2546, 21486, 2475, 2573, 2011, 8031, 2000, 2122, 3563, 13833, 1998, 10723, 1996, 9230, 1998, 13791, 1997, 11311, 4442, 1999, 1996, 27166, 2015, 8670, 2546, 21486, 2475, 1010, 2174, 1010, 20817, 2062, 13228, 2135, 2000, 3563, 1055, 2487, 2361, 13833, 2084, 13097, 2368, 3148, 1010, 3391, 2000, 1055, 2487, 2361, 1011, 1015, 1998, 1055, 2487, 2361, 1011, 1019, 1010, 1998, 2003, 2947, 3517, 2000, 4468, 1048, 24335, 8458, 26915, 2401, 1006, 2019, 19470, 2135, 2659, 2504, 1997, 1048, 24335, 8458, 28788, 1010, 1037, 2828, 1997, 2317, 2668, 3526, 1010, 1999, 1996, 2668, 1007, 1010, 2028, 1997, 1996, 2062, 2691, 2217, 3896, 1997, 13097, 2368, 3148, 1996, 7818, 4403, 1017, 2817, 1006, 13316, 2102, 24096, 28756, 22203, 22932, 1007, 2003, 2881, 2000, 12826, 1996, 21150, 1998, 3808, 1997, 8670, 2546, 21486, 2475, 6431, 2173, 5092, 1999, 5022, 2007, 11867, 5244, 2057, 2298, 2830, 2000, 6631, 1996, 3463, 2012, 1996, 9046, 14925, 18886, 5244, 3519, 1010, 1998, 4067, 2035, 1997, 1996, 2817, 6818, 1998, 14766, 1524, 6846, 28228, 2015, 2003, 2036, 1996, 9338, 1997, 13097, 2368, 3148, 1006, 10346, 24141, 16339, 2094, 1007, 1010, 2029, 2001, 4844, 2011, 1996, 1057, 1055]\n",
            "359\n",
            "is tensor:  True\n",
            "tensor([[ 2055, 13097,  2368,  3148,  1012,  2013,  5796,  2739,  2651,  1010,\n",
            "          2257,  2756,  1010,  2355,  1024, 14686, 13097,  2368,  3148,  1011,\n",
            "          2066,  7242,  3065,  5770,  1999,  3905,  6555,  5796,  5022,  1999,\n",
            "          4403,  1017,  3979,  1999,  2229, 19953,  1010,  8065,  5022,  2007,\n",
            "          3905,  6555,  3674,  8040,  3917, 12650,  1006, 11867,  5244,  1007,\n",
            "          2040,  2020,  5845,  2007,  8670,  2546, 21486,  2475,  1006, 10668,\n",
            "         10698,  5302,  2094,  1007,  1010,  1037, 11867, 12053, 20049,  2638,\n",
            "          1011,  1015,  1011, 17344,  1006,  1055,  2487,  2361,  1007, 24054,\n",
            "          1010,  1999,  1037,  4403,  1017,  6612,  3979,  3662,  1037,  6022,\n",
            "          4359,  3891,  2005, 11980, 14967,  4102,  2000,  2173,  5092,  1010,\n",
            "          6846, 28228,  2015,  3728,  2623,  8670,  2546, 21486,  2475,  2003,\n",
            "          1037, 13228, 16913, 20350,  1997,  3563,  4127,  1997,  1996,  1055,\n",
            "          2487,  2361, 10769,  2023, 10769,  2003,  4141,  2179,  2012,  1996,\n",
            "          3302,  1997, 11311,  4442,  2008, 29543,  1998, 19653,  4053,  1999,\n",
            "          1996,  2430,  6091,  2291,  1006, 27166,  2015,  1007,  1010,  2877,\n",
            "          2000,  3279,  1997,  3853,  1999,  5796,  5022,  2714,  2000, 13097,\n",
            "          2368,  3148,  1006, 10346, 24141, 16339,  2094,  1007,  1010,  8670,\n",
            "          2546, 21486,  2475,  2573,  2011,  8031,  2000,  2122,  3563, 13833,\n",
            "          1998, 10723,  1996,  9230,  1998, 13791,  1997, 11311,  4442,  1999,\n",
            "          1996, 27166,  2015,  8670,  2546, 21486,  2475,  1010,  2174,  1010,\n",
            "         20817,  2062, 13228,  2135,  2000,  3563,  1055,  2487,  2361, 13833,\n",
            "          2084, 13097,  2368,  3148,  1010,  3391,  2000,  1055,  2487,  2361,\n",
            "          1011,  1015,  1998,  1055,  2487,  2361,  1011,  1019,  1010,  1998,\n",
            "          2003,  2947,  3517,  2000,  4468,  1048, 24335,  8458, 26915,  2401,\n",
            "          1006,  2019, 19470,  2135,  2659,  2504,  1997,  1048, 24335,  8458,\n",
            "         28788,  1010,  1037,  2828,  1997,  2317,  2668,  3526,  1010,  1999,\n",
            "          1996,  2668,  1007,  1010,  2028,  1997,  1996,  2062,  2691,  2217,\n",
            "          3896,  1997, 13097,  2368,  3148,  1996,  7818,  4403,  1017,  2817,\n",
            "          1006, 13316,  2102, 24096, 28756, 22203, 22932,  1007,  2003,  2881,\n",
            "          2000, 12826,  1996, 21150,  1998,  3808,  1997,  8670,  2546, 21486,\n",
            "          2475,  6431,  2173,  5092,  1999,  5022,  2007, 11867,  5244,  2057,\n",
            "          2298,  2830,  2000,  6631,  1996,  3463,  2012,  1996,  9046, 14925,\n",
            "         18886,  5244,  3519,  1010,  1998,  4067,  2035,  1997,  1996,  2817,\n",
            "          6818,  1998, 14766,  1524,  6846, 28228,  2015,  2003,  2036,  1996,\n",
            "          9338,  1997, 13097,  2368,  3148,  1006, 10346, 24141, 16339,  2094,\n",
            "          1007,  1010,  2029,  2001,  4844,  2011,  1996,  1057,  1055]])\n",
            "tensor([[ 0.7869,  0.8409, -1.1051]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.4532, 0.4784, 0.0683]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmj8KUQ9qGDb",
        "colab_type": "code",
        "outputId": "0e0f91d5-cf72-4ed8-a976-4bfde1d7c5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#preprocess all the messages (texts)\n",
        "new_messages = []\n",
        "index = 0\n",
        "for message in messages:\n",
        "  msg = pre_process_text(message, drug_info[index])\n",
        "  msg = process_tokens(msg, tokenizer, return_tensor=True)\n",
        "  new_messages.append(msg)\n",
        "  index += 1\n",
        "  \n",
        "print(len(new_messages))\n",
        "assert(len(new_messages) == len(messages))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UekiHepHeQLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting input data for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "#X = np.array(new_messages)\n",
        "X = new_messages\n",
        "Y = np.array(sentiments)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGXzLpJCe5mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#changing Y to one-hot encoded values\n",
        "#pd.get_dummies returns data frames. \n",
        "Y_train = pd.get_dummies(Y_train).values\n",
        "Y_test = pd.get_dummies(Y_test).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bkw4hSyfE2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 256\n",
        "temp_tensor_type = type(torch.Tensor())\n",
        "\n",
        "#class that will hold training data\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, x_y_data, transform=None):\n",
        "    self.x_y_data = x_y_data\n",
        "    self.transform = transform\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    #prepare input\n",
        "    input_item = self.x_y_data[0][index]\n",
        "    input_tensor = input_item \n",
        "    '''if type(input_item) != temp_tensor_type:\n",
        "      ids_text = process_tokens(input_item, self.tokenizer, \n",
        "                              max_seq_length)\n",
        "      input_tensor = torch.tensor(ids_text)'''\n",
        "    \n",
        "    #prepare output\n",
        "    output = self.x_y_data[1][index]\n",
        "    output_tensors = [torch.from_numpy(output)]  \n",
        "    \n",
        "    return input_tensor, output_tensors[0]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x_y_data[0])\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5YIIdwOmvzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#form datasets\n",
        "batch_size = 16\n",
        "\n",
        "train_lists = [X_train, Y_train]\n",
        "test_lists = [X_test, Y_test]\n",
        "\n",
        "training_dataset = TextDataset(x_y_data = train_lists)\n",
        "test_dataset = TextDataset(x_y_data= test_lists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chwK8ONTVTyd",
        "colab_type": "code",
        "outputId": "261cbd10-f2a5-4427-e492-64a8a7efce90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#form data loaders dicts for training loops\n",
        "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=False, num_workers = 0),\n",
        "                   'val': torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers = 0)}\n",
        "\n",
        "dataset_sizes = {'train' : len(train_lists[0]),\n",
        "                'val' : len(test_lists[0])}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDkYYgSgHyPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3f96904-3166-43db-b24f-0289c8960744"
      },
      "source": [
        "dataset_sizes['val']"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEecS4hMWZlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits_arr = []\n",
        "labels_arr = []\n",
        "logits_val_arr = []\n",
        "#train method\n",
        "def train(model, criterion, optimizer, scheduler, num_epochs = 25):\n",
        "  start_time = time.time()\n",
        "  print('starting training process. time: ', start_time)\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = 100\n",
        "  best_acc = 0.0\n",
        "  \n",
        "  #for every epoch\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
        "    print('---------')\n",
        "    \n",
        "    global labels_arr, logits_arr, logits_val_arr\n",
        "    labels_arr, logits_arr, logits_val_arr = [], [], []\n",
        "    \n",
        "    #for every phase - train & validation\n",
        "    for phase in ['train', 'val']:\n",
        "      \n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        model.train()\n",
        "      else:\n",
        "        #set model to eval state in validation mode\n",
        "        model.eval()\n",
        "        \n",
        "      running_loss = 0.0\n",
        "      accuracy = 0\n",
        "      match_count = 0\n",
        "      \n",
        "      for features, labels in dataloaders_dict[phase]:\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        #start from zero grad\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #track history only in training phase\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          logits = model(features)\n",
        "          logits = F.softmax(logits, dim=1)\n",
        "          \n",
        "          #[0] gives max vals, [1] gives max indices, max(dim=1) for horizontal\n",
        "          labels_max_indices = torch.max(labels.float(), 1)[1] \n",
        "          \n",
        "          loss = criterion(logits, labels_max_indices)\n",
        "          \n",
        "          #do backprop only in training phase\n",
        "          if phase=='train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        #metrics\n",
        "        running_loss += loss.item() * features.size(0)\n",
        "        max_label_indices = torch.max(labels, 1)[1]\n",
        "        max_logit_indices = torch.max(logits, 1)[1]\n",
        "        matches = (max_label_indices == max_logit_indices)\n",
        "        match_count += torch.sum(matches)\n",
        "        \n",
        "        logits_arr.append(max_logit_indices)\n",
        "        labels_arr.append(max_label_indices)\n",
        "        \n",
        "        if phase=='val':\n",
        "          logits_val_arr.append(logits)\n",
        "        \n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      accuracy = match_count.double() / dataset_sizes[phase]\n",
        "        \n",
        "      print('{} total loss: {:.4f}'.format(phase, epoch_loss))\n",
        "      print('{} ACCURACY: {:.4f}'.format(phase, accuracy))\n",
        "      \n",
        "      #see if this is the best from last time\n",
        "      if phase=='val' and epoch_loss < best_loss:\n",
        "        print('saving with loss of {}'.format(epoch_loss))\n",
        "        print('improved over previous best: {}'.format(best_loss))\n",
        "        best_loss = epoch_loss\n",
        "        best_acc = accuracy\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        torch.save(model.state_dict(), 'bert_model_state_text_classific.pth')\n",
        "        \n",
        "  time_elapsed = time.time() - start_time\n",
        "  print('training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, \n",
        "                                                       time_elapsed % 60))\n",
        "  print('best val acc.: {:.4f}, val loss: {:.4f}'.format(best_acc, best_loss))\n",
        "  \n",
        "  #return the model with best loss weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgWcFvPDoy5G",
        "colab_type": "code",
        "outputId": "b4c28206-3a74-4e99-ebf1-c6da3cb4e2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#move model to device (gpu if any)\n",
        "model.to(device)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFDbp28Mo1gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning rate settings\n",
        "lrLast = 0.001\n",
        "lrMain = 0.00001\n",
        "optimizer = optim.Adam([{\"params\": model.bert.parameters(), \"lr\": lrMain},\n",
        "                       {\"params\": model.classifier.parameters(), \"lr\": lrLast}])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkzpAdR8Zih_",
        "colab_type": "code",
        "outputId": "8832ff10-9b1e-492f-b37f-3abd17c21973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# execute training\n",
        "model_ft = train(model, criterion, optimizer, exp_lr_scheduler, num_epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting training process. time:  1568405264.258274\n",
            "Epoch 0/19\n",
            "---------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Nbns0M2nmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save final model (best selected) to disk\n",
        "torch.save(model_ft.state_dict(), 'drive/My Drive/Colab Notebooks/DrugData/bert_model_state_text_classific_best.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkt1kGpzJwuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whmWjlvfIjwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking percentage of prediction for each label\n",
        "counts = {}\n",
        "corrects = {}\n",
        "for index in range(len(labels_arr)):\n",
        "  inner_index = 0\n",
        "  for item in labels_arr[index]:\n",
        "    item = int(item)\n",
        "    if item in counts:\n",
        "      counts[item] += 1\n",
        "    else:\n",
        "      counts[item] = 1\n",
        "      \n",
        "    if item == int(logits_arr[index][inner_index]):\n",
        "      if item in corrects:\n",
        "        corrects[item] += 1\n",
        "      else:\n",
        "        corrects[item] = 1\n",
        "    inner_index += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUnnitxfKdPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(counts)\n",
        "print(corrects)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkeUnmb7JKVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "outer_index = 160\n",
        "for batch_arr in logits_val_arr:\n",
        "  inner_index = 0\n",
        "  for arr in batch_arr:\n",
        "    li = []\n",
        "    for item in arr:\n",
        "      li.append(float(item))#logit values\n",
        "    li.append(int(labels_arr[outer_index][inner_index]))#original\n",
        "    li.append(int(logits_arr[outer_index][inner_index]))#predicted\n",
        "    results.append(li)\n",
        "    inner_index +=1\n",
        "  outer_index += 1\n",
        "  \n",
        "print(len(results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwluqpUKL98N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdrHZT8CMTcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(labels_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da0vWprikAU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt('drive/My Drive/Colab Notebooks/DrugData/model_labels_vs_logits_3200_1.csv', np.array(results), delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8MCH-n8lhSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}